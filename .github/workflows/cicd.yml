name: CICD
on: push
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up JDK 11
      uses: actions/setup-java@v4
      with:
        java-version: '17'
        distribution: 'temurin'

    - name: Cache Maven dependencies
      uses: actions/cache@v4
      with:
        path: ~/.m2/repository
        key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
        restore-keys: |
          ${{ runner.os }}-maven-
          
    - name: Build with Maven
      working-directory: ./initial
      run: mvn --batch-mode clean test package

    - name: Upload build artifact
      uses: actions/upload-artifact@v4
      with:
       name: app-jar
       path: initial/target/*.jar
  
  deploy:
    needs: build
    runs-on: ubuntu-latest
    
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      ECR_REPOSITORY: ${{ secrets.ECR_REPOSITORY }}
      IMAGE_TAG: ${{ github.sha }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Download JAR artifact
      uses: actions/download-artifact@v4
      with:
        name: app-jar
        path: initial/target
        
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}
        # role-to-assume: arn:aws:iam::557690581666:role/GitHubActionsEKSRole
        # role-session-name: GitHubActions
        # audience: sts.amazonaws.com

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1

    - name: Build Docker image
      working-directory: ./initial
      run: |
        docker build -t $ECR_REPOSITORY:$IMAGE_TAG .

    - name: Run Trivy vulnerability scan
      uses: aquasecurity/trivy-action@0.30.0
      with:
        image-ref: '${{ env.ECR_REPOSITORY }}:${{ env.IMAGE_TAG }}'
        format: 'sarif'
        output: 'trivy-results.sarif'
        exit-code: 0 # Set to 1 if you want to fail on vulnerabilities
        severity: 'CRITICAL,HIGH'

    # - name: Upload Trivy results to GitHub Security Requires GitHub Pro Version
    #   uses: github/codeql-action/upload-sarif@v2
    #   with:
    #     sarif_file: 'trivy-results.sarif'

    - name: Tag Docker image
      run: |
        docker tag $ECR_REPOSITORY:$IMAGE_TAG ${{ steps.login-ecr.outputs.registry }}/$ECR_REPOSITORY:$IMAGE_TAG

    - name: Push Docker image to ECR
      run: |
        docker push ${{ steps.login-ecr.outputs.registry }}/$ECR_REPOSITORY:$IMAGE_TAG

    - name: Install Cosign
      uses: sigstore/cosign-installer@v3.3.0
      with:
        cosign-release: 'v2.2.2'

    - name: Sign Docker image with Cosign
      env:
        COSIGN_EXPERIMENTAL: "1"
        COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}
        COSIGN_KEY: ${{ secrets.COSIGN_KEY }}
      run: |
        IMAGE="${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ env.IMAGE_TAG }}"
        echo "$COSIGN_KEY" > cosign.key
        cosign sign --key cosign.key $IMAGE

    - name: Update kubeconfig for EKS
      run: |
        aws eks update-kubeconfig --region $AWS_REGION --name ${{ secrets.EKS_CLUSTER_NAME }}

    - name: Apply namespace-scoped RBAC for spring-batch and cicd-deployer
      working-directory: ./initial
      run: |
        kubectl apply -f rbac.yaml

    - name: Create ConfigMap for SQL
      working-directory: ./initial
      run: |
        kubectl create configmap init-sql-script --from-file=src/main/resources/schema.sql --dry-run=client -o yaml | kubectl apply -f -
        
    - name: Apply MySQL ConfigMap, Secret, and Deployment
      working-directory: ./initial
      run: |
        kubectl apply -f mysql-configmap.yaml
        kubectl apply -f secrets.yaml
        kubectl apply -f mysql-deployment.yaml

    - name: Wait for MySQL readiness
      run: |
        echo "Waiting for MySQL pod..."
        kubectl wait --for=condition=ready pod -l app=demo-app --timeout=120s

    - name: Install Helm
      run: |
        curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
        helm version

    - name: Add Falco and Kyverno Helm repos
      run: |
        helm repo add falcosecurity https://falcosecurity.github.io/charts
        helm repo add kyverno https://kyverno.github.io/kyverno/

    - name: Update Helm repos
      run: helm repo update

    - name: Install Falco with HTTP output enabled
      run: |
        helm upgrade --install falco -n falco falcosecurity/falco \
          --set falcosidekick.enabled=true \
          --set falcosidekick.webui.enabled=true \
          --set auditLog.enabled=true \
          --set falco.jsonOutput=true \
          --set falco.fileOutput.enabled=true \
          --set falco.http_output.enabled=true \
          --set falco.http_output.url="http://falco-falcosidekick.falco.svc.cluster.local:2801" \
          --create-namespace \
          --set falcosidekick.config.slack.webhookurl="https://hooks.slack.com/services/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" \
          --set config.slack.minimumpriority="warning"

    # - name: Install Kyverno
    #   run: |
    #     helm upgrade --install kyverno kyverno/kyverno \
    #       --namespace kyverno --create-namespace --wait \
    #       --debug \
    #       --timeout=300s
   
    - name: Uninstall Kyverno (if exists)
      continue-on-error: true
      run: |
        kubectl delete -f https://github.com/kyverno/kyverno/releases/download/v1.11.1/install.yaml

    - name: Install Kyverno
      working-directory: ./initial
      run: |
        kubectl apply -f https://github.com/kyverno/kyverno/releases/download/v1.11.1/install.yaml --server-side --force-conflicts
    
    - name: Wait for Kyverno to be ready
      run: |
        echo "Waiting for Kyverno pods to be ready..."
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/part-of=kyverno --namespace kyverno --timeout=120s

    - name: Create ECR pull secret for Kyverno
      run: |
        ECR_PASSWORD=$(aws ecr get-login-password --region $AWS_REGION)
        kubectl create secret docker-registry ecr-creds \
          --docker-server=${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.$AWS_REGION.amazonaws.com \
          --docker-username=AWS \
          --docker-password="$ECR_PASSWORD" \
          -n kyverno \
          --dry-run=client -o yaml | kubectl apply -f -


    - name: Patch Kyverno admission controller for ECR auth
      run: |
        kubectl patch deploy kyverno-admission-controller -n kyverno \
          --type=json \
          -p='[{"op": "add", "path": "/spec/template/spec/imagePullSecrets", "value": [{"name": "ecr-creds"}]}]'

    - name: Patch Kyverno background controller for ECR auth
      run: |
        kubectl patch deploy kyverno-background-controller -n kyverno \
          --type=json \
          -p='[{"op": "add", "path": "/spec/template/spec/imagePullSecrets", "value": [{"name": "ecr-creds"}]}]'

    - name: Restart Kyverno pods
      run: |
        kubectl rollout restart deploy -n kyverno kyverno-admission-controller
        kubectl rollout restart deploy -n kyverno kyverno-background-controller

    - name: Apply Cosign public key ConfigMap
      working-directory: ./initial
      run: |
        kubectl apply -f kyverno-configmap.yaml

    - name: Apply Kyverno verify-image policy
      working-directory: ./initial
      run: |
        kubectl apply -f kyverno-policy.yaml

    - name: Delete existing job if it exists
      run: |
        kubectl delete job batch-job --ignore-not-found

    - name: Inject image into CronJob manifest
      working-directory: ./initial
      run: |
        export IMAGE="${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ env.IMAGE_TAG }}"
        envsubst < app-deployment.yaml > final-cronjob.yaml

    - name: Apply CronJob to EKS
      working-directory: ./initial
      run: |
        kubectl apply -f final-cronjob.yaml